# ğŸ™ï¸ Pocket TTS Server v1.0

[![GitHub](https://img.shields.io/badge/GitHub-ai--joe--git/pocket--tts--server-blue?logo=github)](https://github.com/ai-joe-git/pocket-tts-server)
![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.8+-green)
![License](https://img.shields.io/badge/license-MIT-yellow)

A lightweight, real-time voice cloning and chat server with OpenAI-compatible API. Clone any voice with just 20 seconds of audio and chat with AI using that voice instantly.

**[ğŸ“¥ Download](https://github.com/ai-joe-git/pocket-tts-server) | [ğŸ› Report Issue](https://github.com/ai-joe-git/pocket-tts-server/issues) | [â­ Star](https://github.com/ai-joe-git/pocket-tts-server)**

---

## âœ¨ Screenshots

### Voice Chat Interface
![Voice Chat](screenshot-voice-chat.png)
*Real-time voice chat with streaming text and audio*

### Voice Library & Upload
![Voice Library](screenshot-voice-library.png)
*Upload voices via drag-and-drop or browse. Auto-converts MP3/OGG/FLAC to WAV.*

### LLM Configuration
![Settings](screenshot-settings.png)
*Easy configuration for any OpenAI-compatible LLM backend*

---

## ğŸš€ Quick Start (Windows - 3 Steps)

### Step 1: Install
Double-click **`install_pocket_tts.bat`**
- Installs Python (if needed)
- Creates virtual environment
- Installs all dependencies automatically

### Step 2: Run
Double-click **`run_pocket_tts.bat`**
- Starts the server
- Opens browser automatically (or go to `http://localhost:8000`)

### Step 3: Chat
- Select a voice from the sidebar
- Go to **Voice Chat**
- Start typing!

**That's it!** No coding required.

---

## ğŸ­ Key Features

### ğŸ—£ï¸ Voice Cloning
- **Any voice** - Upload 15-20 seconds of clear audio
- **Auto-conversion** - MP3/OGG/FLAC â†’ WAV automatically
- **Smart trimming** - Long audio auto-trimmed to 20s (prevents gibberish)
- **Archive system** - Originals saved to `voices-celebrities-archive/`

### ğŸ’¬ Real-Time Voice Chat
- **Streaming text** - Words appear as LLM generates them
- **Streaming audio** - Audio plays sentence-by-sentence
- **No waiting** - First audio in 2-3 seconds
- **Sequential playback** - Sentences queue and play in order

### ğŸ”Œ OpenAI Compatible
- Drop-in replacement for OpenAI TTS API
- Works with OpenWebUI, SillyTavern, and other clients
- `/v1/audio/speech`, `/v1/chat/completions`, `/v1/audio/voices`

### âš¡ Performance
- 4000 token support for long responses
- 180-second timeout for slow LLMs
- CPU optimized (GPU optional)
- 76+ voices included (celebrities, characters, custom)

---

## ğŸ“‹ Requirements

### Automatic (Windows)
Just run `install_pocket_tts.bat` - handles everything!

### Manual Installation
```bash
# 1. Clone repository
git clone https://github.com/ai-joe-git/pocket-tts-server.git
cd pocket-tts-server

# 2. Install dependencies
pip install -r requirements.txt

# 3. Start server
python pocket_tts_api.py
```

**System Requirements:**
- Windows 10/11 (Linux/Mac supported with manual setup)
- Python 3.8+
- 4GB+ RAM
- Audio: WAV, MP3, OGG, FLAC supported

---

## ğŸ¤ Setting Up Voices

### Method 1: Web Upload (Easiest)
1. Open `http://localhost:8000`
2. Click **Voice Library** or current voice in sidebar
3. Drag & drop audio file or click to browse
4. Name your voice
5. Done! Ready in seconds

### Method 2: Manual Copy
1. Copy audio files to `voices-celebrities/`
2. Restart server
3. Files auto-convert to WAV format
4. Originals archived automatically

**Voice Quality Tips:**
- âœ… **Best length:** 15-20 seconds
- âœ… **Max length:** 20 seconds (longer files auto-trimmed)
- âœ… **Clear audio:** Single speaker, no background noise
- âœ… **Why trim?** Prevents gibberish from overly long samples

---

## ğŸ¤– Connecting to LLM

### Recommended: llama.cpp

**1. Start LLM server:**
```bash
./server -m your-model.gguf -c 4096 --port 8080
```

**2. Configure Pocket TTS:**
- Open web interface
- Go to **Settings** tab
- Enable **LLM Integration**
- Set URL: `http://127.0.0.1:8080/v1/chat/completions`
- Save

**3. Start chatting:**
- Select **Voice Chat** tab
- Type message
- Watch text stream in real-time
- Hear voice respond immediately!

**Other LLM Options:**
- Ollama (`http://localhost:11434/v1/chat/completions`)
- text-generation-webui
- Any OpenAI-compatible API

---

## ğŸ“š API Documentation

### Generate Speech
```bash
curl -X POST http://localhost:8000/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, this is a test!",
    "voice": "barack-obama",
    "response_format": "wav"
  }' \
  --output speech.wav
```

### List Voices
```bash
curl http://localhost:8000/v1/audio/voices
```

Response:
```json
{
  "voices": [
    {"voice_id": "barack-obama", "name": "Barack Obama"},
    {"voice_id": "donald-trump", "name": "Donald Trump"}
  ]
}
```

### Voice Chat (Non-Streaming)
```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Tell me a joke"}],
    "voice": "elon-musk"
  }'
```

### Voice Chat (Streaming - Real-Time)
```bash
curl -X POST http://localhost:8000/v1/chat/completions/stream \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Tell me a story"}],
    "voice": "donald-trump"
  }'
```

**SSE Response Format:**
- `data: {"type": "text", "content": "word "}` - Streaming text
- `data: {"type": "audio", "data": "base64...", "chunk": 0}` - Audio per sentence  
- `data: {"type": "done"}` - Complete

---

## ğŸ› ï¸ Configuration

Edit `config.json` or use Settings page:

```json
{
  "server": {
    "host": "localhost",
    "port": 8000
  },
  "llm": {
    "enabled": true,
    "api_url": "http://127.0.0.1:8080/v1/chat/completions",
    "api_key": "",
    "model": "llama-3",
    "system_prompt": "You are a helpful AI assistant."
  }
}
```

---

## ğŸ”§ Troubleshooting

### âŒ No Audio Output
- [ ] Check voice selected in sidebar
- [ ] Verify files in `voices-celebrities/` folder
- [ ] Check browser console (F12) for errors
- [ ] Restart server after adding voices

### âŒ Text Gets Cut Off
- [ ] This was fixed in v1.0 (4000 token limit)
- [ ] Check if your LLM has its own token limit

### âŒ Audio Sounds Weird/Garbled  
- [ ] Voice sample too long - check `voices-celebrities-archive/`
- [ ] Re-upload 15-20 second clip
- [ ] Ensure single speaker, clear audio

### âŒ LLM Connection Fails
- [ ] Verify LLM server running on correct port
- [ ] Check API URL matches your LLM (Settings page)
- [ ] Timeout is 180s - increase if needed

---

## ğŸ“ Project Structure

```
pocket-tts-server/
â”œâ”€â”€ pocket_tts_api.py           # Main server (FastAPI)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Web interface
â”œâ”€â”€ voices-celebrities/         # Active voices (WAV)
â”œâ”€â”€ voices-celebrities-archive/ # Original MP3/OGG files
â”œâ”€â”€ config.json                 # Settings
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ install_pocket_tts.bat      # Windows installer
â”œâ”€â”€ run_pocket_tts.bat          # Windows launcher
â””â”€â”€ fix_dependencies.bat        # Repair tool
```

---

## ğŸ¯ How It Works

### Streaming Architecture
1. **User sends message** â†’ LLM starts generating
2. **Text streams** â†’ Word-by-word as LLM generates
3. **Sentence complete** â†’ TTS generates audio for that sentence
4. **Audio queues** â†’ Plays sequentially (no overlap)
5. **Next sentence** â†’ Continues while previous audio plays

### Voice Processing Pipeline
1. **Upload** â†’ MP3/OGG/FLAC/WAV accepted
2. **Convert** â†’ Auto-convert to WAV (24kHz, mono)
3. **Trim** â†’ Cut to 20 seconds max (prevents gibberish)
4. **Archive** â†’ Move original to archive folder
5. **Cache** â†’ Load voice state for fast access

---

## ğŸ¤ Contributing

Ideas for v1.1:
- ğŸšï¸ Voice effects (pitch, speed, reverb)
- ğŸ­ Voice blending/mixing
- ğŸŒ Multi-language support
- ğŸ“± Mobile app
- âš¡ WebRTC for ultra-low latency

**Open an issue** with feature requests or bugs!

---

## ğŸ“„ License

MIT License - Free for personal and commercial use.

---

## ğŸ™ Credits

- [pocket-tts](https://github.com/kyutai-labs/pocket-tts) - The TTS engine
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - Recommended LLM backend

---

**Made with â¤ï¸ by the AI community**

*Note: Not affiliated with OpenAI. API compatibility for convenience only.*

**[â¬†ï¸ Back to Top](#readme-top)**
